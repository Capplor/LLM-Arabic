from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain.memory import ConversationBufferMemory
from langchain_core.prompts import PromptTemplate
from langchain.chains import ConversationChain
from langchain_openai import ChatOpenAI
from langchain.output_parsers.json import SimpleJsonOutputParser
from langsmith import Client
from langsmith import traceable
from langsmith.run_helpers import get_current_run_tree
from streamlit_feedback import streamlit_feedback
from streamlit_gsheets import GSheetsConnection
from functools import partial
import gspread
import json
from google.oauth2.service_account import Credentials

import os
import sys

from llm_config import LLMConfig

import streamlit as st
import pandas as pd
from datetime import datetime

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø³Ø±Ø§Ø± streamlit Ù„ØªØ¹ÙŠÙŠÙ† Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø¨ÙŠØ¦Ø©
os.environ["OPENAI_API_KEY"] = st.secrets.get('OPENAI_API_KEY', '')
os.environ["LANGCHAIN_API_KEY"] = st.secrets.get('LANGCHAIN_API_KEY', '')
os.environ["LANGCHAIN_PROJECT"] = st.secrets.get('LANGCHAIN_PROJECT', '')
os.environ["LANGCHAIN_TRACING_V2"] = 'true'
os.environ["SPREADSHEET_URL"] = st.secrets.get('SPREADSHEET_URL', '')

# ØªØ­Ù„ÙŠÙ„ ÙˆØ³ÙŠØ·Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ù„Ù Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯
input_args = sys.argv[1:]
if len(input_args):
    config_file = input_args[0]
else:
    config_file = st.secrets.get("CONFIG_FILE", "ToM_config.toml")
print(f"Configuring app using {config_file}...\n")

# Ø¥Ù†Ø´Ø§Ø¡ prompts Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯
llm_prompts = LLMConfig(config_file)

## Ù…ÙØªØ§Ø­ ØªØ¨Ø³ÙŠØ· Ù„Ù„Ø£ØºØ±Ø§Ø¶ Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©
DEBUG = False

# Ø¥Ø¹Ø¯Ø§Ø¯ Langsmith
smith_client = Client()

st.set_page_config(page_title="Ø¨ÙˆØª Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø©", page_icon="ğŸ“–")
st.title("ğŸ“– Ø¨ÙˆØª Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø©")


## ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ÙÙŠ session_state Ø¹Ù†Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„
if 'run_id' not in st.session_state:
    st.session_state['run_id'] = None

if 'agentState' not in st.session_state:
    st.session_state['agentState'] = "start"
if 'consent' not in st.session_state:
    st.session_state['consent'] = False
if 'exp_data' not in st.session_state:
    st.session_state['exp_data'] = True

## Ø¶Ø¨Ø· Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¹Ù†Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„
if 'llm_model' not in st.session_state:
    st.session_state.llm_model = "gpt-4o"

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
msgs = StreamlitChatMessageHistory(key="langchain_messages")
memory = ConversationBufferMemory(memory_key="history", chat_memory=msgs)
conn = st.connection("gsheets", type=GSheetsConnection)
spreadsheet_url = st.secrets.get("SPREADSHEET_URL")
if not spreadsheet_url:
    st.error("Ù„Ù… ÙŠØªÙ… ØªÙˆÙÙŠØ± Ø±Ø§Ø¨Ø· Google Sheet ÙÙŠ secrets!")


# ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚Ø§Ù„Ø¨ Ø£ÙØ¶Ù„ Ù„Ù†Ù…ÙˆØ°Ø¬ gpt-4o
if st.session_state['llm_model'] == "gpt-4o":
    prompt_datacollection = llm_prompts.questions_prompt_template


def getData(testing=False):
    """ÙŠØ¬Ù…Ø¹ Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©. """

    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ø°Ù‡ Ø£ÙˆÙ„ Ù…Ø±Ø©ØŒ Ù†Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© Ù…Ù† Ø§Ù„ÙˆØ¯Ø¬Øª
    if len(msgs.messages) == 0:
        msgs.add_ai_message(llm_prompts.questions_intro)

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ù‚Ù… Ø§Ù„Ù…Ø´Ø§Ø±Ùƒ Ù…Ù† Ø£ÙˆÙ„ Ø±Ø³Ø§Ù„Ø© Ø¨Ø´Ø±ÙŠØ©
    if 'participant_id' not in st.session_state:
        for msg in msgs.messages:
            if msg.type == "human" and not st.session_state.get('participant_id'):
                st.session_state['participant_id'] = msg.content.strip()
                break

    # Ø¥Ø¹Ø§Ø¯Ø© Ø¹Ø±Ø¶ Ø¢Ø®Ø± Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù€ AI-Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø¹Ø¯ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØµÙØ­Ø©
    if len(msgs.messages) >= 2:
        last_two_messages = msgs.messages[-1:]
    else:
        last_two_messages = msgs.messages

    for msg in last_two_messages:
        if msg.type == "ai":
            with entry_messages:
                st.chat_message(msg.type).write(msg.content)

    # Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ù…ÙØ¯Ø®Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯
    if prompt:
        with entry_messages:
            st.chat_message("human").write(prompt)

            # ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… langchain
            response = conversation.invoke(input=prompt)

            # ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ±Ø¬Ø¹ Ø§Ù„Ù€ prompt "FINISHED" Ø¹Ù†Ø¯ Ø§ÙƒØªÙ…Ø§Ù„ Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if "FINISHED" in response.get('response', ''):
                st.divider()
                # Ø§Ø³ØªØ®Ø¯Ù… Ù†Øµ Ø§Ù„Ø®Ø§ØªÙ…Ø© Ø§Ù„Ù…Ø¹Ø±Ù‘Ù ÙÙŠ Ù…Ù„Ù Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ (Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)
                st.chat_message("ai").write(llm_prompts.questions_outro)

                # Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªÙ„Ø®ÙŠØµ
                st.session_state.agentState = "summarise"
                summariseData(testing)
            else:
                st.chat_message("ai").write(response.get("response", ""))


def save_to_google_sheets(package, worksheet_name="Sheet1"):
    """
    ÙŠØ­ÙØ¸ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª ÙˆØ§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª ÙˆØ§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø¥Ù„Ù‰ Google Sheets.
    """
    try:
        gsheets_secrets = st.secrets["connections"]["gsheets"]
        spreadsheet_url = gsheets_secrets["spreadsheet"]

        credentials_dict = {
            "type": gsheets_secrets["type"],
            "project_id": gsheets_secrets["project_id"],
            "private_key_id": gsheets_secrets["private_key_id"],
            "private_key": gsheets_secrets["private_key"].replace("\\n", "\n"),
            "client_email": gsheets_secrets["client_email"],
            "client_id": gsheets_secrets["client_id"],
            "auth_uri": gsheets_secrets["auth_uri"],
            "token_uri": gsheets_secrets["token_uri"],
            "auth_provider_x509_cert_url": gsheets_secrets["auth_provider_x509_cert_url"],
            "client_x509_cert_url": gsheets_secrets["client_x509_cert_url"],
        }

        scopes = [
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive"
        ]

        credentials = Credentials.from_service_account_info(credentials_dict, scopes=scopes)
        gc = gspread.authorize(credentials)
        sh = gc.open_by_url(spreadsheet_url)

        try:
            worksheet = sh.worksheet(worksheet_name)
        except gspread.exceptions.WorksheetNotFound:
            worksheet = sh.add_worksheet(title=worksheet_name, rows=100, cols=20)

        answers = package.get("answer_set", {})
        new_row = [
            answers.get("participant_id", ""),  # participant number
            answers.get("what", ""),  # Q1
            answers.get("context", ""),  # Q2
            answers.get("environment",""),  # Q3
            answers.get("procedure", ""), # Q4
            answers.get("mental_states", ""), # Q5
            answers.get("mind_vs_emo", ""), # Q6 
            answers.get("understanding", ""), # Q7
            answers.get("categorical_vs_continuous", ""), # Q8
            answers.get("similarity", ""),  #Q9
            answers.get("social_perception", ""),  #Q10
            package.get("scenarios_all", {}).get("col1", ""),
            package.get("scenarios_all", {}).get("col2", ""),
            package.get("scenarios_all", {}).get("col3", ""),
            package.get("scenario", ""),
            package.get("preference_feedback", "")
        ]
        

        existing = worksheet.get_all_values()
        headers = [
            "participant_number", "q1", "q2", "q3", "q4", "q5", "q6", "q7","q8","q9", "q10",
            "scenario_1", "scenario_2", "scenario_3", "final_scenario", "preference_feedback"
        ]

        if not existing or existing[0] != headers:
            worksheet.insert_row(headers, 1)

        worksheet.append_row(new_row)

        st.success("ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ Google Sheets!")
        return True

    except Exception as e:
        st.error(f"ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Google Sheet: {e}")
        if "quota" in str(e).lower():
            st.info("Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ø³Ø¨Ø¨ Ø­Ø¯ Ø§Ù„Ø­ØµÙ‘Ø© ÙÙŠ Google Sheets. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ù‹Ø§.")
        elif "permission" in str(e).lower():
            st.info("ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ù†Ø­ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø¯Ù…Ø© Ø¥Ø°Ù† Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Google Sheet.")
        return False


def extractChoices(msgs, testing):
    """
    ÙŠØ³ØªØ¯Ø¹ÙŠ LLM Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ù† Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙˆØ¥Ø±Ø¬Ø§Ø¹Ù‡Ø§ ÙƒÙ…Ø´Ø±ÙˆØ¹ JSON.
    """
    try:
        extraction_llm = ChatOpenAI(
            temperature=0.1,
            model=st.session_state.llm_model,
            openai_api_key=openai_api_key
        )

        extraction_template = PromptTemplate(
            input_variables=["conversation_history"],
            template=llm_prompts.extraction_prompt_template
        )

        json_parser = SimpleJsonOutputParser()
        extractionChain = extraction_template | extraction_llm | json_parser

        if testing:
            conversation_text = llm_prompts.example_messages
        else:
            conversation_text = "\n".join([
                f"{m.type}: {m.content}" for m in msgs.messages
            ])

        extractedChoices = extractionChain.invoke({"conversation_history": conversation_text})

        extractedChoices["participant_id"] = st.session_state.get('participant_id', '')

        expected_keys = [
            "what", "context", "environment", "procedure", "mental_states", "mind_vs_emo",
            "understanding", "categorical_vs_continuous", "similarity", "social_perception"
        ]

        for key in expected_keys:
            if key not in extractedChoices:
                extractedChoices[key] = ""

        return extractedChoices

    except Exception as e:
        st.error(f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª: {e}")
        return {
            "participant_id": st.session_state.get('participant_id', ''),
            "what": "",
            "context": "",
            "environment": "",
            "procedure": "",
            "mental_states": "",
            "mind_vs_emo": "",
            "understanding": "",
            "categorical_vs_continuous": "",
            "similarity": "",
            "social_perception": ""
        }


def collectFeedback(answer, column_id, scenario):
    """ÙŠØ­ÙØ¸ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨ÙƒÙ„ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø¹Ù„Ù‰ Langsmith."""

    st.session_state.temp_debug = "called collectFeedback"

    score_mappings = {
        "thumbs": {"ğŸ‘": 1, "ğŸ‘": 0},
        "faces": {"ğŸ˜€": 1, "ğŸ™‚": 0.75, "ğŸ˜": 0.5, "ğŸ™": 0.25, "ğŸ˜": 0},
    }
    scores = score_mappings.get(answer['type'], {})

    score = scores.get(answer['score'])

    run_id = st.session_state['run_id']

    if DEBUG:
        st.write(run_id)
        st.write(answer)

    if score is not None:
        feedback_type_str = f"{answer['type']} {score} {answer['text']} \n {scenario}"

        st.session_state.temp_debug = feedback_type_str

        payload = f"{answer['score']} ØªÙ‚ÙŠÙŠÙ… Ù„Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ: \n {scenario} \n Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰: \n {llm_prompts.one_shot}"

        smith_client.create_feedback(
            run_id=run_id,
            value=payload,
            key=column_id,
            score=score,
            comment=answer['text']
        )
    else:
        st.warning("Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª ØºÙŠØ± ØµØ§Ù„Ø­Ø©.")


@traceable
def summariseData(testing=False):
    """ÙŠØ£Ø®Ø° Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© ÙˆÙŠÙˆÙ„Ø¯ Ø«Ù„Ø§Ø« Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨."""
    prompt_template = PromptTemplate.from_template(llm_prompts.main_prompt_template)
    json_parser = SimpleJsonOutputParser()
    chain = prompt_template | chat | json_parser

    if testing:
        answer_set = extractChoices(msgs, True)
    else:
        answer_set = extractChoices(msgs, False)

    if DEBUG:
        st.divider()
        st.chat_message("ai").write("**ØªØµØ­ÙŠØ­ Ø£Ø®Ø·Ø§Ø¡ (DEBUG)** â€” Ø£Ø¹ØªÙ‚Ø¯ Ø£Ù† Ù‡Ø°Ø§ Ù…Ù„Ø®Ù‘Øµ Ø¬ÙŠØ¯ Ù„Ù…Ø§ Ù‚Ù„Øª... ØªØ­Ù‚Ù‚ Ø¥Ù† ÙƒØ§Ù† ØµØ­ÙŠØ­Ù‹Ø§!")
        st.chat_message("ai").json(answer_set)

    st.session_state['answer_set'] = answer_set

    with entry_messages:
        if testing:
            st.markdown(":red[DEBUG Ù…ÙØ¹Ù„ â€” Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø±Ø³Ø§Ø¦Ù„ ØªØ¬Ø±ÙŠØ¨ÙŠØ©]")

        st.divider()
        st.chat_message("ai").write("ÙŠØ¨Ø¯Ùˆ Ø£Ù†Ù†ÙŠ Ø¬Ù…Ø¹Øª ÙƒÙ„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª! Ø³Ø£Ø­Ø§ÙˆÙ„ Ø§Ù„Ø¢Ù† ØªÙ„Ø®ÙŠØµ Ù…Ø§ Ù‚Ù„ØªÙ‡ ÙÙŠ Ø«Ù„Ø§Ø«Ø© Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª. ğŸ˜Š\nØ§Ø®ØªØ± Ù…Ø§ ÙŠØ¹Ø¬Ø¨Ùƒ Ø£ÙƒØ«Ø±.")

        progress_text = "Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª..."
        bar = st.progress(0, text=progress_text)

    summary_answers = {key: answer_set.get(key, "") for key in llm_prompts.summary_keys}

    st.session_state.response_1 = chain.invoke({
        "persona": llm_prompts.personas[0],
        "one_shot": llm_prompts.one_shot,
        "end_prompt": llm_prompts.extraction_task
    } | summary_answers)
    run_1 = get_current_run_tree()

    bar.progress(33, progress_text)

    st.session_state.response_2 = chain.invoke({
        "persona": llm_prompts.personas[1],
        "one_shot": llm_prompts.one_shot,
        "end_prompt": llm_prompts.extraction_task
    } | summary_answers)
    run_2 = get_current_run_tree()

    bar.progress(66, progress_text)

    st.session_state.response_3 = chain.invoke({
        "persona": llm_prompts.personas[2],
        "one_shot": llm_prompts.one_shot,
        "end_prompt": llm_prompts.extraction_task
    } | summary_answers)
    run_3 = get_current_run_tree()

    bar.progress(99, progress_text)

    if DEBUG:
        st.session_state.run_collection = {
            "run1": run_1,
            "run2": run_2,
            "run3": run_3
        }

    st.session_state.run_id = run_1.id
    st.session_state["agentState"] = "review"

    st.button("Ø£Ù†Ø§ Ø¬Ø§Ù‡Ø² â€” Ø£Ø±Ù†ÙŠ Ø§Ù„Ù†ØªØ§Ø¦Ø¬!", key='progressButton')


def testing_reviewSetUp():
    """ØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø®ØªØ¨Ø§Ø±ÙŠØ© Ø¨Ø³ÙŠØ·Ø© Ù„Ø¹Ø±Ø¶ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©."""
    text_scenarios = {
        "s1": "ÙƒÙ†Øª Ø£Ø­Ø§ÙˆÙ„ Ø£Ù† Ø£ØªØ¹Ù„Ù… Ø´ÙŠØ¦Ù‹Ø§ ØªÙ‚Ù†ÙŠÙ‹Ø§ ÙˆØ£Ø®Ø¨Ø±Øª Ø·Ù„Ø§Ø¨ÙŠ Ø¨Ø°Ù„ÙƒØŒ Ù„ÙƒÙ† Ù„Ù… ÙŠØªØ¹Ø§Ù…Ù„ÙˆØ§ Ø¨Ø¬Ø¯ÙŠØ© ÙˆØ³Ø¨Ø¨ÙˆØ§ Ù„ÙŠ Ø¥Ø­Ø±Ø§Ø¬Ù‹Ø§. Ø´Ø¹Ø±Øª Ø¨Ø§Ù„Ø§Ù†Ø²Ø¹Ø§Ø¬ ÙˆØ§ØªØ®Ø°Øª Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø¥Ø¯Ø§Ø±ÙŠØ© Ø¨Ø¹Ø¯ Ø°Ù„Ùƒ.",
        "s2": "Ù†Ø´Ø±Øª Ø¹Ù† ØµØ¹ÙˆØ¨ØªÙŠ ÙÙŠ ØªØ¹Ù„Ù… Ù…Ù‡Ø§Ø±Ø© ØªÙ‚Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ù†ØªØ±Ù†ØªØŒ ÙˆØªÙˆÙ‚Ø¹ Ø£Ù† ÙŠØ¯Ø¹Ù…Ù†ÙŠ Ø²Ù…Ù„Ø§Ø¦ÙŠ Ù„ÙƒÙ†Ù‡ Ø¶Ø­ÙƒÙˆØ§ Ø¨Ø¯Ù„Ù‹Ø§ Ù…Ù† Ø°Ù„ÙƒØŒ ÙØ´Ø¹Ø±Øª Ø¨Ø¥Ø­Ø¨Ø§Ø·.",
        "s3": "Ø­Ø§ÙˆÙ„Øª Ù…Ø´Ø§Ø±ÙƒØ© ØªØ­Ø¯Ù Ù…Ù‡Ù†ÙŠ Ø¹Ø¨Ø± Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØŒ Ù„ÙƒÙ† Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø¨Ø¹Ø¶ ÙƒØ§Ù†Øª Ø³Ù„Ø¨ÙŠØ© Ù…Ù…Ø§ Ø¬Ø¹Ù„Ù†ÙŠ Ø£ØªØ®Ø° Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ØªØµØ­ÙŠØ­ÙŠØ© Ù„Ø§Ø­Ù‚Ù‹Ø§."
    }

    st.session_state.response_1 = {'output_scenario': text_scenarios['s1']}
    st.session_state.response_2 = {'output_scenario': text_scenarios['s2']}
    st.session_state.response_3 = {'output_scenario': text_scenarios['s3']}


def click_selection_yes(button_num, scenario):
    st.session_state.scenario_selection = button_num

    if 'answer_set' not in st.session_state:
        st.session_state['answer_set'] = extractChoices(msgs, False)

    scenario_dict = {
        'col1': st.session_state.response_1['output_scenario'],
        'col2': st.session_state.response_2['output_scenario'],
        'col3': st.session_state.response_3['output_scenario'],
    }

    st.session_state.scenario_package = {
        'scenario': scenario,
        'answer_set': st.session_state['answer_set'],
        'judgment': st.session_state.get('scenario_decision', ''),
        'scenarios_all': scenario_dict,
        'preference_feedback': st.session_state.get('feedback_text', '')
    }

    st.session_state['agentState'] = 'finalise'
    st.rerun()


def click_selection_no():
    st.session_state['scenario_judged'] = True


def sliderChange(name, *args):
    st.session_state['scenario_judged'] = False
    st.session_state['scenario_decision'] = st.session_state[name]


def scenario_selection(popover, button_num, scenario):
    with popover:
        if "scenario_judged" not in st.session_state:
            st.session_state['scenario_judged'] = True

        st.markdown(f"Ø¥Ù„Ù‰ Ø£ÙŠ Ù…Ø¯Ù‰ ÙŠØ¹Ø¨Ø± Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ {button_num} Ø¹Ù…Ù‘Ø§ ÙƒÙ†Øª ØªÙÙƒØ± Ø¨Ù‡ØŸ")
        sliderOptions = ["Ù„Ø§ ÙŠÙ…Ø«Ù„ Ù‚ØµØ¯ÙŠ", "Ø¨Ø­Ø§Ø¬Ø© Ù„Ø¨Ø¹Ø¶ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª", "Ø¬ÙŠØ¯ Ù„ÙƒÙ† Ø£Ø±ÙŠØ¯ ØªØºÙŠÙŠØ±Ù‡ Ù‚Ù„ÙŠÙ„Ø§Ù‹", "Ø¬Ø§Ù‡Ø² ÙƒÙ…Ø§ Ù‡Ùˆ!"]
        slider_name = f'slider_{button_num}'

        st.select_slider("Ù‚ÙÙŠÙ‘ÙÙ… Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ", label_visibility='hidden', key=slider_name, options=sliderOptions, on_change=sliderChange, args=(slider_name,))

        c1, c2 = st.columns(2)

        c1.button("Ø£ÙƒÙ…Ù„ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ ğŸ‰", key=f'yeskey_{button_num}', on_click=click_selection_yes, args=(button_num, scenario), disabled=st.session_state['scenario_judged'])
        c2.button("ÙÙŠ Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø©ØŒ Ø£ÙˆØ¯ ØªØ¬Ø±Ø¨Ø© Ø¢Ø®Ø± ğŸ¤¨", key=f'nokey_{button_num}', on_click=click_selection_no)


def reviewData(testing=False):
    if testing:
        testing_reviewSetUp()

    if 'scenario_selection' not in st.session_state:
        st.session_state['scenario_selection'] = '0'

    if st.session_state['scenario_selection'] == '0':
        col1, col2, col3 = st.columns(3)

        disable = {}
        for col in ['col1_fb', 'col2_fb', 'col3_fb']:
            feedback_data = st.session_state.get(col)
            if isinstance(feedback_data, dict) and 'score' in feedback_data:
                disable[col] = feedback_data.get('score')
            else:
                disable[col] = None

        with col1:
            st.header("Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù¡")
            st.write(st.session_state.response_1['output_scenario'])
            streamlit_feedback(
                feedback_type="thumbs",
                optional_text_label="[Ø§Ø®ØªÙŠØ§Ø±ÙŠ] ÙŠØ±Ø¬Ù‰ Ø´Ø±Ø­ Ø±Ø£ÙŠÙƒ",
                align='center',
                key="col1_fb",
                disable_with_score=disable['col1_fb'],
                on_submit=collectFeedback,
                args=('col1', st.session_state.response_1['output_scenario'])
            )

        with col2:
            st.header("Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù¢")
            st.write(st.session_state.response_2['output_scenario'])
            streamlit_feedback(
                feedback_type="thumbs",
                optional_text_label="[Ø§Ø®ØªÙŠØ§Ø±ÙŠ] ÙŠØ±Ø¬Ù‰ Ø´Ø±Ø­ Ø±Ø£ÙŠÙƒ",
                align='center',
                key="col2_fb",
                disable_with_score=disable['col2_fb'],
                on_submit=collectFeedback,
                args=('col2', st.session_state.response_2['output_scenario'])
            )

        with col3:
            st.header("Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù£")
            st.write(st.session_state.response_3['output_scenario'])
            streamlit_feedback(
                feedback_type="thumbs",
                optional_text_label="[Ø§Ø®ØªÙŠØ§Ø±ÙŠ] ÙŠØ±Ø¬Ù‰ Ø´Ø±Ø­ Ø±Ø£ÙŠÙƒ",
                align='center',
                key="col3_fb",
                disable_with_score=disable['col3_fb'],
                on_submit=collectFeedback,
                args=('col3', st.session_state.response_3['output_scenario'])
            )

        st.divider()
        st.chat_message("ai").write(
            "Ø§Ù„Ø±Ø¬Ø§Ø¡ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ø£Ø¹Ù„Ø§Ù‡ØŒ Ø£Ø¹Ø·Ù†ÙŠ Ù…Ù„Ø§Ø­Ø¸Ø§ØªÙƒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ğŸ‘/ğŸ‘ØŒ Ø«Ù… Ø§Ø®ØªØ± Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ø°ÙŠ ØªØ±Ø§Ù‡ Ø§Ù„Ø£Ù‚Ø±Ø¨ Ù„Ù…Ø§ Ù‚ØµØ¯ØªÙ‡."
        )

        b1, b2, b3 = st.columns(3)
        scenario_selection(b1.popover("Ø§Ø®ØªØ± Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù¡"), "1", st.session_state.response_1['output_scenario'])
        scenario_selection(b2.popover("Ø§Ø®ØªØ± Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù¢"), "2", st.session_state.response_2['output_scenario'])
        scenario_selection(b3.popover("Ø§Ø®ØªØ± Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù£"), "3", st.session_state.response_3['output_scenario'])

    else:
        selected_idx = st.session_state['scenario_selection']
        if selected_idx == '1':
            st.session_state['selected_scenario_text'] = st.session_state.response_1['output_scenario']
        elif selected_idx == '2':
            st.session_state['selected_scenario_text'] = st.session_state.response_2['output_scenario']
        elif selected_idx == '3':
            st.session_state['selected_scenario_text'] = st.session_state.response_3['output_scenario']

        st.session_state['agentState'] = 'finalise'


def updateFinalScenario(new_scenario):
    st.session_state.scenario_package['scenario'] = new_scenario
    st.session_state.scenario_package['judgment'] = "Ø¬Ø§Ù‡Ø² ÙƒÙ…Ø§ Ù‡Ùˆ!"



def finaliseScenario_ar(package):
    """
    Arabic version: Displays final scenario, answers, and collects feedback.
    Saves everything to Google Sheets when submitted.
    """
    # Check if we've already submitted - if so, show only the completion page
    if st.session_state.get('submitted', False):
        show_completion_page_ar()
        return
    
    st.header("Ù…Ø±Ø§Ø¬Ø¹Ø© ÙˆØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª")
    
    # Show final scenario
    st.subheader("Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
    scenario_text = st.text_area(
        "Ù‚Ù… Ø¨ØªØ­Ø±ÙŠØ± Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±:",
        value=package.get("scenario", "Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø¨Ø¹Ø¯."),
        height=200,
        key="final_scenario_editor_ar"
    )
    
    # Update the scenario if edited
    if scenario_text != package.get("scenario", ""):
        package["scenario"] = scenario_text
        st.session_state.scenario_package = package
    
    # Feedback input
    st.divider()
    st.subheader("Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…ÙˆØ¬Ø²Ø©")
    feedback_text = st.text_area(
        "ÙŠØ±Ø¬Ù‰ Ù…Ø´Ø§Ø±ÙƒØ© Ø³Ø¨Ø¨ Ø§Ø®ØªÙŠØ§Ø±Ùƒ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ø®Øµ Ø¹Ù„Ù‰ Ø§Ù„Ø¢Ø®Ø±ÙŠÙ†:",
        value=st.session_state.get('feedback_text', ''),
        height=100,
        key="final_feedback_ar"
    )
    
    # Store feedback in session state
    st.session_state['feedback_text'] = feedback_text
    package["preference_feedback"] = feedback_text
    
    # Get redirect URL
    redirect_url = st.secrets.get("REDIRECT_URL", "")
    
    # Show the redirect section BEFORE the submit button
    if redirect_url:
        st.markdown("---")
        st.markdown("### Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©")
        st.markdown("Ø¨Ø¹Ø¯ ØªÙ‚Ø¯ÙŠÙ… Ù…Ù„Ø§Ø­Ø¸Ø§ØªÙƒØŒ ÙŠØ±Ø¬Ù‰ Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ø§Ø³ØªØ¨ÙŠØ§Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ. Ø¥Ø°Ø§ Ù„Ù… ÙŠØ¸Ù‡Ø± Ù„Ùƒ Ø§Ù„Ø´Ø§Ø´Ø© Ø£ÙŠ Ø´ÙŠØ¡ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø¹ÙˆØ¯Ø© Ø¥Ù„Ù‰ Prolific ÙˆØ§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¨Ø§Ø­Ø«")
    st.markdown("---")
    
    # Submit button - NO FORM
    if st.button("ØªÙ‚Ø¯ÙŠÙ… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª", type="primary", key="submit_feedback_ar"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ..."):
            if save_to_google_sheets(package):
                # Clear everything and show success
                st.empty()
                
                st.balloons()
                st.success("ğŸ‰ Ø´ÙƒØ±Ø§Ù‹ Ù„Ùƒ! ØªÙ… ØªÙ‚Ø¯ÙŠÙ… Ù…Ù„Ø§Ø­Ø¸Ø§ØªÙƒ Ø¨Ù†Ø¬Ø§Ø­.")
                
                # Show redirect immediately after success
                if redirect_url:
                    st.markdown("## Ù…Ø¨Ø±ÙˆÙƒ! Ù„Ù‚Ø¯ Ø£ÙƒÙ…Ù„Øª Ø§Ù„Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©.")
                    st.markdown("### Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: Ø§Ø³ØªØ¨ÙŠØ§Ù† Ù…ÙˆØ¬Ø²")
                    st.markdown("ÙŠØ±Ø¬Ù‰ Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ø§Ø³ØªØ¨ÙŠØ§Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø±Ø§Ø¨Ø· Ø£Ø¯Ù†Ø§Ù‡:")
                    
                    # Create a prominent button
                    st.markdown(
                        f'<div style="text-align: center; margin: 30px 0;">'
                        f'<a href="{redirect_url}" target="_blank">'
                        f'<button style="background-color: #4CAF50; color: white; padding: 20px 40px; border: none; border-radius: 10px; cursor: pointer; font-size: 20px; margin: 20px 0; box-shadow: 0 4px 8px rgba(0,0,0,0.2);">'
                        f'ğŸš€ Ø£ÙƒÙ…Ù„ Ø§Ù„Ø§Ø³ØªØ¨ÙŠØ§Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ'
                        f'</button>'
                        f'</a>'
                        f'</div>',
                        unsafe_allow_html=True
                    )
                    
                    st.info("Ø³ÙŠØªÙ… ÙØªØ­ Ø§Ù„Ø§Ø³ØªØ¨ÙŠØ§Ù† ÙÙŠ Ø¹Ù„Ø§Ù…Ø© ØªØ¨ÙˆÙŠØ¨ Ø¬Ø¯ÙŠØ¯Ø©. ÙŠØ±Ø¬Ù‰ Ø¥ÙƒÙ…Ø§Ù„Ù‡ Ø§Ù„Ø¢Ù† Ù„Ø¥Ù†Ù‡Ø§Ø¡ Ù…Ø´Ø§Ø±ÙƒØªÙƒ.")
                    
                    # Alternative link
                    st.markdown(f"**Ø¥Ø°Ø§ Ù„Ù… ÙŠØ¹Ù…Ù„ Ø§Ù„Ø²Ø±ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ø§Ù„Ø±Ø§Ø¨Ø·:**")
                    st.markdown(f'<a href="{redirect_url}" target="_blank" style="color: #1f77b4; text-decoration: underline;">{redirect_url}</a>', unsafe_allow_html=True)
                
                # Update state
                st.session_state['submitted'] = True
                st.session_state['agentState'] = 'completed'
                
                # Stop further execution to prevent the form from showing again
                st.stop()
            else:
                st.error("Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")

def show_completion_page_ar():
    """
    Arabic version: Simple completion page as fallback
    """
    st.balloons()
    st.success("ğŸ‰ Ø´ÙƒØ±Ø§Ù‹ Ù„Ùƒ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ©!")
    
    redirect_url = st.secrets.get("REDIRECT_URL", "")
    if redirect_url:
        st.markdown(f"""
        ### Ø§Ù„Ø§Ø³ØªØ¨ÙŠØ§Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        
        ÙŠØ±Ø¬Ù‰ Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ø§Ø³ØªØ¨ÙŠØ§Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:
        [Ø§Ù†Ù‚Ø± Ù‡Ù†Ø§ Ù„ÙØªØ­]({redirect_url})
        """)
    
    if st.button("Ø¨Ø¯Ø¡ Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø©"):
        for key in list(st.session_state.keys()):
            if key != 'consent':
                del st.session_state[key]
        st.session_state['agentState'] = 'start'
        st.experimental_rerun()

def stateAgent():
    testing = False

    if st.session_state['agentState'] == 'start':
        getData(testing)

    elif st.session_state['agentState'] == 'summarise':
        summariseData(testing)

    elif st.session_state['agentState'] == 'review':
        reviewData(testing)

    elif st.session_state['agentState'] == 'finalise':
        if 'scenario_package' not in st.session_state:
            st.error("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø­Ø²Ù…Ø© Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø¹ÙˆØ¯Ø© ÙˆØ§Ø®ØªÙŠØ§Ø± Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ.")
            if st.button("Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ"):
                st.session_state['agentState'] = 'review'
                st.rerun()
            return

        package = st.session_state.scenario_package
        if 'feedback_text' in st.session_state:
            package["preference_feedback"] = st.session_state['feedback_text']

        finaliseScenario(package)

    elif st.session_state['agentState'] == 'completed':
        st.success("Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ø¬Ù„Ø³Ø© Ø¨Ù†Ø¬Ø§Ø­!")
        st.write("Ø´ÙƒØ±Ù‹Ø§ Ù„Ù…Ø´Ø§Ø±ÙƒØªÙƒ ÙÙŠ Ø¯Ø±Ø§Ø³ØªÙ†Ø§.")
        if st.button("Ø¨Ø¯Ø¡ Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø©"):
            for key in list(st.session_state.keys()):
                if key != 'consent':
                    del st.session_state[key]
            st.session_state['agentState'] = 'start'
            st.rerun()


def markConsent():
    st.session_state['consent'] = True


# Ø¥Ø®ÙØ§Ø¡ Ø£ÙŠÙ‚ÙˆÙ†Ø© GitHub Ù„Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ù‡ÙˆÙŠØ©
st.markdown(
"""
    <style>
    [data-testid="stToolbarActions"] {visibility: hidden;}
    </style>
    """,
    unsafe_allow_html=True
)

### Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø© -- Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ Ø´ØºÙ‘Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
if st.session_state['consent']:

    if st.session_state['agentState'] == 'review':
        st.session_state['exp_data'] = False

    entry_messages = st.expander("Ø¬Ù…Ø¹ Ø³Ø±Ø¯ ØªØ¬Ø±Ø¨ØªÙƒ", expanded=st.session_state['exp_data'])

    if st.session_state['agentState'] == 'review':
        review_messages = st.expander("Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª")

    prompt = st.chat_input()

    if "OPENAI_API_KEY" in st.secrets:
        openai_api_key = st.secrets["OPENAI_API_KEY"]
    else:
        openai_api_key = st.sidebar.text_input("Ù…ÙØªØ§Ø­ OpenAI API", type="password")

    if not openai_api_key:
        st.info("Ø£Ø¯Ø®Ù„ Ù…ÙØªØ§Ø­ OpenAI API Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©")
        st.stop()

    chat = ChatOpenAI(temperature=0.3, model=st.session_state.llm_model, openai_api_key=openai_api_key)

    prompt_updated = PromptTemplate(input_variables=["history", "input"], template=prompt_datacollection)

    conversation = ConversationChain(
        prompt=prompt_updated,
        llm=chat,
        verbose=True,
        memory=memory
    )

    stateAgent()

# Ø¥Ø°Ø§ Ù„Ù… Ù†Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø© Ø¨Ø¹Ø¯ â€” Ø§Ø·Ù„Ø¨ Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø©
else:
    print("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø©!")
    consent_message = st.container()
    with consent_message:
        st.markdown(llm_prompts.intro_and_consent)
        st.button("Ø£ÙˆØ§ÙÙ‚", key="consent_button", on_click=markConsent)
